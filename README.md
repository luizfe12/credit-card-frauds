# Detec√ß√£o de Fraudes em Cart√µes de Cr√©dito

![Status](https://img.shields.io/badge/status-conclu%C3%ADdo-brightgreen)

## üìñ Vis√£o Geral do Projeto

Este projeto tem como objetivo desenvolver um modelo de Machine Learning capaz de identificar transa√ß√µes fraudulentas em cart√µes de cr√©dito. Devido √† natureza do problema, lidamos com um dataset altamente desbalanceado, onde o n√∫mero de fraudes representa uma porcentagem m√≠nima do total de transa√ß√µes (~0.17%).

O desafio principal √© construir um classificador que maximize a detec√ß√£o de fraudes reais (alto *recall*) e, ao mesmo tempo, minimize o n√∫mero de alarmes falsos, evitando o bloqueio de transa√ß√µes leg√≠timas (alta *precis√£o*).

## üìä Dataset

O conjunto de dados utilizado foi o ["Credit Card Fraud Detection"](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud), dispon√≠vel no Kaggle. Ele cont√©m transa√ß√µes feitas por cart√µes de cr√©dito europeus em setembro de 2013.

**Caracter√≠sticas do Dataset:**
- **N√∫mero de Transa√ß√µes:** 284,807
- **Features:** 31 colunas no total.
  - `Time` e `Amount`: As √∫nicas features n√£o anonimizadas.
  - `V1` a `V28`: Features anonimizadas, resultantes de uma transforma√ß√£o de An√°lise de Componentes Principais (PCA).
  - `Class`: A vari√°vel alvo, onde `1` representa uma fraude e `0` uma transa√ß√£o normal.

## üõ†Ô∏è Tecnologias Utilizadas

- **Linguagem:** Python 3
- **Bibliotecas Principais:**
  - `Pandas` para manipula√ß√£o e an√°lise de dados.
  - `Matplotlib` e `Seaborn` para visualiza√ß√£o de dados.
  - `Scikit-learn` para pr√©-processamento, modelagem e avalia√ß√£o.
  - `Imbalanced-learn` para t√©cnicas de reamostragem (SMOTE).
  - `XGBoost` para modelagem com Gradient Boosting.

## üöÄ Metodologia

O projeto foi estruturado seguindo as principais etapas de um fluxo de trabalho de Machine Learning:

1.  **An√°lise Explorat√≥ria (EDA):** Verifica√ß√£o da propor√ß√£o de classes, an√°lise de valores ausentes e estudo da distribui√ß√£o das features `Time` e `Amount`.
2.  **Pr√©-processamento:**
    - Padroniza√ß√£o (`StandardScaler`) das colunas `Time` e `Amount` para que tivessem a mesma escala das features `V1-V28`.
3.  **Balanceamento de Dados:**
    - Aplica√ß√£o da t√©cnica **SMOTE (Synthetic Minority Over-sampling Technique)** *apenas no conjunto de treino* para criar exemplos sint√©ticos da classe minorit√°ria (fraude), evitando que o modelo ficasse enviesado para a classe majorit√°ria.
4.  **Modelagem e Treinamento:**
    - Divis√£o dos dados em conjuntos de treino e teste (80/20), utilizando estratifica√ß√£o para manter a propor√ß√£o de classes.
    - Treinamento e compara√ß√£o de tr√™s algoritmos de classifica√ß√£o:
      1.  Regress√£o Log√≠stica (como baseline)
      2.  Random Forest
      3.  XGBoost
5.  **Avalia√ß√£o:**
    - An√°lise da Matriz de Confus√£o.
    - Foco nas m√©tricas de **Precis√£o (Precision)**, **Revoca√ß√£o (Recall)** e **F1-Score**, que s√£o mais adequadas para datasets desbalanceados do que a Acur√°cia.

## üìà An√°lise dos Resultados

### Distribui√ß√£o dos Valores de Transa√ß√£o

O boxplot abaixo mostra que, em geral, as transa√ß√µes fraudulentas (Classe 1) tendem a envolver valores monet√°rios menores em compara√ß√£o com as transa√ß√µes normais (Classe 0). No entanto, ambas as classes possuem uma grande quantidade de outliers.

![Distribui√ß√£o dos Valores de Transa√ß√£o por Classe](./images/image_4b38cd.png)

### Comparativo de Performance dos Modelos

A tabela abaixo resume o desempenho dos modelos na tarefa de classificar a **Classe 1 (Fraude)** no conjunto de teste:

| Modelo | Precis√£o (Fraude) | Recall (Fraude) | F1-Score (Fraude) | Conclus√£o Pr√°tica |
| :--- | :---: | :---: | :---: | :--- |
| Regress√£o Log√≠stica | 5% | **95%** | 10% | Pega quase todas as fraudes, mas gera alarmes falsos demais. Invi√°vel. |
| **Random Forest** | **85%** | 87% | **86%** | **O melhor equil√≠brio.** Pega a maioria das fraudes com poucos erros. |
| XGBoost | 77% | 88% | 82% | √ìtimo em pegar fraudes, mas com mais alarmes falsos que o Random Forest. |

O modelo **Random Forest** se destacou como o grande vencedor, apresentando o melhor equil√≠brio entre Precis√£o e Recall, refletido no maior F1-Score. Ele foi capaz de identificar **87% das fraudes reais**, com uma taxa de acerto de **85%** em suas previs√µes positivas.

## üèÅ Conclus√£o

O projeto demonstrou com sucesso a capacidade de construir um modelo eficaz para a detec√ß√£o de fraudes. O uso da t√©cnica SMOTE foi crucial para lidar com o desbalanceamento dos dados, permitindo que modelos como o Random Forest aprendessem os padr√µes das transa√ß√µes fraudulentas de forma robusta.

O modelo final (Random Forest) representa uma ferramenta valiosa, capaz de economizar recursos financeiros ao mesmo tempo que minimiza o impacto negativo sobre a experi√™ncia de clientes leg√≠timos.

## üöÄ Como Executar o Projeto

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
    cd seu-repositorio
    ```
2.  **Crie um ambiente virtual (recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```
3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Execute o notebook ou script principal:**
    Abra o arquivo `.ipynb` no Jupyter Notebook/Lab ou execute o script `.py`.

## ‚úçÔ∏è Autor

- **Luiz Felipe da Silva**
- **LinkedIn:** [https://www.linkedin.com/in/luiz-felipe-da-silva12](https://www.linkedin.com/in/luiz-felipe-da-silva12)
- **GitHub:** [https://github.com/luizfe12](https://github.com/luizfe12)# credit-card-frauds
